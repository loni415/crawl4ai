# VLLM Configuration for Qwen2.5-VL-7B-Instruct
# This is an example configuration file for using vllm with Crawl4AI

# LLM Provider - follows the format "provider/model"
LLM_PROVIDER=qwen/qwen2.5-vl-7b-instruct

# Base URL for the vllm container
# Use the container name as hostname and http:// (not https://)
# The /v1 path is required for OpenAI-compatible endpoints
LLM_BASE_URL=http://vllm-qwen2.5-vl-7b:8000/v1

# API Key - vllm doesn't require authentication, so any value works
VLLM_API_KEY=VLLM

# Optional: Customize LLM parameters
# LLM_TEMPERATURE=0.7
# LLM_MAX_TOKENS=4096